{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Importing Libraries:\n",
    "=="
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils import data\n",
    "from torchvision.transforms import functional as F\n",
    "import torchvision\n",
    "\n",
    "from sklearn.metrics import jaccard_score as jsc\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib.path import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print('GPU is available!')\n",
    "    device = \"cuda\"\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor') \n",
    "else:\n",
    "    print('GPU is not available!')\n",
    "    device = \"cpu\""
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GPU is not available!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading Data:\n",
    "=="
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "def transform(x):\n",
    "    return  torchvision.transforms.functional.to_tensor(x)\n",
    "\n",
    "class DataSet(torch.utils.data.Dataset):\n",
    "    def float_maker(self, a):\n",
    "        if a[0]=='(':\n",
    "            return a[1:]\n",
    "        if a[-1]==')':\n",
    "            return a[:-1]\n",
    "        return a\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.image_names= os.listdir('./Data_ML/image_chips/')\n",
    "    def __getitem__(self, index):\n",
    "        image = plt.imread(os.path.join(os.getcwd(),'Data_ML','image_chips',self.image_names[index]))\n",
    "        mask = pd.read_csv(os.path.join(os.getcwd(),'Data_ML','target_feature_AOI',self.image_names[index][:-4]+'.csv'))\n",
    "        coordinates = mask.WKT.values[0][16:-3].split(',')\n",
    "        # convert coordinates into a masked image (750x750x1)\n",
    "        points = ([tuple(self.float_maker(i)  for i in x.split()) for x in coordinates])\n",
    "        h , w = 750, 750\n",
    "        point_path = Path(points)\n",
    "        x, y = np.mgrid[:h, :w]\n",
    "        y = - y\n",
    "        coors=np.hstack((x.reshape(-1, 1), y.reshape(-1,1)))\n",
    "        masked_image = (point_path.contains_points(coors))\n",
    "        first = torchvision.transforms.Resize((768,768))(transform(image))\n",
    "        second = (torchvision.transforms.functional.to_tensor(masked_image.reshape(h,w)).int())\n",
    "        return (first,second)\n",
    "    def __len__(self):\n",
    "        return 100 #cause we have 100 samples, change this if needed"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "# input training images are 750x750x3 and are 100 in number\n",
    "# test image is 5x5 images (hence 3750x3750x3), we need to output a masked image with 0s and 1s\n",
    "input_channels = 3 \n",
    "max_channels = 512\n",
    "output_classes = 1\n",
    "\n",
    "batch_size = 8 #make it 8 once bug fixing is over\n",
    "train_size = 100 # divide train:val by 70:30 probably\n",
    "test_size = 25 # if we break the super test image into individual images to run our model on\n",
    "\n",
    "\n",
    "train_dataLoader = data.DataLoader(\n",
    "    DataSet(), #need to get DataSet to make train and CV both\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers= 0\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating Module:\n",
    "=="
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "class UNetConv(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super().__init__()\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, output_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(output_channels, output_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv2(x)\n",
    "class DownConv(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super().__init__()\n",
    "        self.conv_down = nn.Sequential(\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            UNetConv(input_channels, output_channels)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv_down(x)\n",
    "class UpConv(nn.Module): #whatever is commented is the actual correct code, the line above it is bug fixing ## torch.cat is giving issues\n",
    "    def __init__(self, input_channels, output_channels, padding=0):\n",
    "        super().__init__()\n",
    "        self.conv_up = nn.Sequential(\n",
    "            nn.ConvTranspose2d(input_channels , input_channels // 2, kernel_size=2, stride=2, padding = padding),\n",
    "        )\n",
    "        self.conv_level = nn.Sequential(\n",
    "            #UNetConv(input_channels // 2,output_channels) \n",
    "            UNetConv(input_channels,output_channels) \n",
    "        )\n",
    "    def forward(self, x1, x2):\n",
    "        #return self.conv_level(self.conv_up(x1))\n",
    "        return self.conv_level(torch.cat([x2,self.conv_up(x1)],dim = 1)) \n",
    "class LastConv(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super().__init__()\n",
    "        self.conv_final = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, output_channels, kernel_size=1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv_final(x)\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, input_channels, max_channels):\n",
    "        super(UNet, self).__init__()\n",
    "        self.current_channels = max_channels // 2**4\n",
    "        self.start = UNetConv(input_channels, self.current_channels)\n",
    "        self.current_channels = self.current_channels*2\n",
    "        self.down1 = DownConv(self.current_channels // 2 , self.current_channels)\n",
    "        self.current_channels = self.current_channels*2\n",
    "        self.down2 = DownConv(self.current_channels // 2 , self.current_channels)\n",
    "        self.current_channels = self.current_channels*2\n",
    "        self.down3 = DownConv(self.current_channels // 2 , self.current_channels)\n",
    "        self.current_channels = self.current_channels*2\n",
    "        self.down4 = DownConv(self.current_channels // 2 , self.current_channels)\n",
    "        self.current_channels = self.current_channels // 2\n",
    "        self.up1 = UpConv(self.current_channels * 2, self.current_channels) \n",
    "        self.current_channels = self.current_channels // 2\n",
    "        self.up2 = UpConv(self.current_channels * 2, self.current_channels)\n",
    "        self.current_channels = self.current_channels // 2\n",
    "        self.up3 = UpConv(self.current_channels * 2, self.current_channels)\n",
    "        self.current_channels = self.current_channels // 2\n",
    "        self.up4 = UpConv(self.current_channels * 2, self.current_channels)\n",
    "        self.final = LastConv(self.current_channels,output_classes)\n",
    "    def forward(self, x):\n",
    "        x1 = self.start(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        #x3 = F.pad(x3, (1,1,0,0))\n",
    "        x4 = self.down3(x3)\n",
    "        #x4 = F.pad(x4, (1,0,0,1))\n",
    "        x5 = self.down4(x4)\n",
    "        #x5 = F.pad(x5, (0,0,1,1))\n",
    "        y1 = self.up1(x5,x4)\n",
    "        y2 = self.up2(y1,x3)\n",
    "        y3 = self.up3(y2,x2)\n",
    "        x = self.up4(y3,x1)\n",
    "        return torch.sigmoid(self.final(x))\n",
    "\n",
    "Model = UNet(input_channels, max_channels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training Model:\n",
    "=="
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "epochs = 5\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = 1e-5\n",
    "    def forward(self, y_pred, y_true):\n",
    "        print(y_pred.shape, y_true.shape)\n",
    "        assert y_pred.size() == y_true.size()\n",
    "        y_pred = y_pred[:, 0].contiguous().view(-1)\n",
    "        y_true = y_true[:, 0].contiguous().view(-1)\n",
    "        intersection = (y_pred * y_true).sum()\n",
    "        dsc = (2. * intersection + self.smooth) / (y_pred.sum() + y_true.sum() + self.smooth)\n",
    "        return 1. - dsc\n",
    "\n",
    "loss_func = DiceLoss()\n",
    "optimizer = optim.Adam(Model.parameters(),lr=0.01)\n",
    "loss_sanity = jsc\n",
    "trainLoss = []\n",
    "sanityLosss = []\n",
    "for epoch in range(epochs):  \n",
    "    epochStart = time.time()\n",
    "    runningLoss = 0.0\n",
    "    sanityLoss = 0.0\n",
    "    i = 0\n",
    "    for inputs, labels in tqdm(train_dataLoader): \n",
    "        if(i==3):\n",
    "            break\n",
    "        #i+=1\n",
    "        optimizer.zero_grad()  \n",
    "        outputs = Model(inputs) \n",
    "        outputs = torchvision.transforms.Resize((750,750))(outputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward() \n",
    "        loss_san = loss_sanity(torch.round(outputs).detach().numpy().reshape(-1), labels.detach().numpy().reshape(-1))\n",
    "        nn.utils.clip_grad_norm_(Model.parameters(), 50)\n",
    "        optimizer.step()\n",
    "        runningLoss += loss.item()\n",
    "        sanityLoss += loss_san.item()\n",
    "    runningLoss /= len(inputs) \n",
    "    sanityLoss /= len(inputs)\n",
    "    sanityLosss.append(sanityLoss)\n",
    "    trainLoss.append(runningLoss)\n",
    "    epochEnd = time.time()-epochStart\n",
    "    print('Iteration: {:.0f} /{:.0f}  ;  Training Loss: {:.6f} ; Sanity Loss: {:.6f} ; Time consumed: {:.0f}m {:.0f}s '\\\n",
    "        .format(epoch + 1, epochs, runningLoss, sanityLoss, epochEnd//60, epochEnd%60))   \n",
    "print('Finished Training')"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8d8bb507f3e5429b9907e77bd0c05048"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing Model:\n",
    "=="
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_loss = 0.0\n",
    "for inputs, labels in tqdm(test_dataLoader):\n",
    "    outputs = Model(inputs)\n",
    "    loss = loss_func(outputs, labels)\n",
    "    test_loss += loss.item()\n",
    "test_loss /= len(inputs)\n",
    "print(test_loss)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/Users/siddhant/.vscode/extensions/ms-toolsai.jupyter-2021.8.1013163132/out/client/extension.js:90:320068)",
      "at w.execute (/Users/siddhant/.vscode/extensions/ms-toolsai.jupyter-2021.8.1013163132/out/client/extension.js:90:319389)",
      "at w.start (/Users/siddhant/.vscode/extensions/ms-toolsai.jupyter-2021.8.1013163132/out/client/extension.js:90:315205)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/Users/siddhant/.vscode/extensions/ms-toolsai.jupyter-2021.8.1013163132/out/client/extension.js:90:329732)",
      "at async t.CellExecutionQueue.start (/Users/siddhant/.vscode/extensions/ms-toolsai.jupyter-2021.8.1013163132/out/client/extension.js:90:329272)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d32307ab60c186a8047d52516f214c86ffc4fca0a07f2d9b7e263da528082b42"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('shims': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}