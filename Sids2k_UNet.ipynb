{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Importing Libraries:\n",
    "=="
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils import data\n",
    "from torchvision.transforms import functional as F\n",
    "import torchvision\n",
    "import shutil\n",
    "\n",
    "from sklearn.metrics import jaccard_score as jsc\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib.path import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print('GPU is available!')\n",
    "    device = \"cuda\"\n",
    "    #torch.set_default_tensor_type('torch.cuda.FloatTensor') (else HPC doesn't work)\n",
    "else:\n",
    "    print('GPU is not available!')\n",
    "    device = \"cpu\""
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GPU is not available!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hyperparams:\n",
    "=="
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# depth of UNet = 3\n",
    "learning_rate = 1e-5\n",
    "epoch_number = 250\n",
    "batch_size = 16 # make it 2-4 once bug fixing is over\n",
    "train_size = 100 # divide train:val by 70:30 probably\n",
    "test_size = 25 # if we break the super test image into individual images to run our model on\n",
    "img_size = 768 # dimensions to resize input 750x750 into (power of 2^(depth+\\delta) necessary for model to work)\n",
    "max_channels = 512 # gives error if divided by 2 {or more}, not technically max_channel... number of channels after first conv is max_channels / 2^4\n",
    "gradient_clip = 50 # tried 10 and 100 too   \n",
    "dice_alpha = 1e-3 # maybe try 1e-4 and 1.0\n",
    "pretrained = True\n",
    "freeze_layers = 0 # for pretrained model\n",
    "name = 'test'\n",
    "PATH = os.path.join(os.getcwd(),'models/',name+'.pt')\n",
    "bestPATH = os.path.join(os.getcwd(),'models/best_model_'+name+'.pt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading Data:\n",
    "=="
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def transform(x):\n",
    "    return  torchvision.transforms.functional.to_tensor(x)\n",
    "\n",
    "class DataSet(torch.utils.data.Dataset):\n",
    "    def float_maker(self, a):\n",
    "        if a[0]=='(':\n",
    "            return a[1:]\n",
    "        if a[-1]==')':\n",
    "            return a[:-1]\n",
    "        return a\n",
    "    def __init__(self, mode):\n",
    "        super().__init__()\n",
    "        self.image_names= os.listdir('./Data_ML/image_chips/')\n",
    "        self.mode = mode\n",
    "        # self.image_names= os.listdir('/content/drive/MyDrive/Data_ML/image_chips/') for google.colab\n",
    "    def __getitem__(self, index):\n",
    "        if(self.mode == 'Train'):\n",
    "            image = plt.imread(os.path.join(os.getcwd(),'Data_ML','image_chips',self.image_names[index]))\n",
    "            mask = pd.read_csv(os.path.join(os.getcwd(),'Data_ML','target_feature_AOI',self.image_names[index][:-4]+'.csv'))\n",
    "            # for google.colab\n",
    "            # image = plt.imread(os.path.join('/content/drive/MyDrive','Data_ML','image_chips',self.image_names[index]))\n",
    "            # mask = pd.read_csv(os.path.join('/content/drive/MyDrive','Data_ML','target_feature_AOI',self.image_names[index][:-4]+'.csv'))\n",
    "            coordinates = mask.WKT.values[0][16:-3].split(',')\n",
    "            points = ([tuple(self.float_maker(i)  for i in x.split()) for x in coordinates])\n",
    "            h , w = 750, 750\n",
    "            point_path = Path(points)\n",
    "            x, y = np.mgrid[:h, :w]\n",
    "            y = - y\n",
    "            coors=np.hstack((x.reshape(-1, 1), y.reshape(-1,1)))\n",
    "            masked_image = (point_path.contains_points(coors))\n",
    "            first = torchvision.transforms.Resize((img_size,img_size))(transform(image))\n",
    "            second = (torchvision.transforms.functional.to_tensor(masked_image.reshape(h,w)).int())\n",
    "            return (first,second)\n",
    "        else:\n",
    "            image = plt.imread(os.path.join(os.getcwd(),'mosaic_test.jpg'))\n",
    "            x,y = (index)//5  , (index+1)%5\n",
    "            if(y==0):   \n",
    "                y=5\n",
    "            img_crop=image[(x)*750:(x+1)*750,(y-1)*750:(y)*750,:]\n",
    "            return torchvision.transforms.Resize((img_size,img_size))(transform(img_crop))\n",
    "    def __len__(self):\n",
    "        if(self.mode=='Train'):\n",
    "            return train_size\n",
    "        else:\n",
    "            return test_size"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# input training images are 750x750x3 and are 100 in number\n",
    "# test image is 5x5 images (hence 3750x3750x3), we need to output a masked image with 0s and 1s\n",
    "input_channels = 3 \n",
    "output_classes = 1\n",
    "\n",
    "train_dataLoader = data.DataLoader(\n",
    "    DataSet('Train'), #need to get DataSet to make train and CV both\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers= 0\n",
    ")\n",
    "test_dataLoader = data.DataLoader(\n",
    "    DataSet('Test'),\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating Module:\n",
    "=="
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "class UNetConv(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super().__init__()\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, output_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(output_channels, output_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv2(x)\n",
    "class DownConv(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super().__init__()\n",
    "        self.conv_down = nn.Sequential(\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            UNetConv(input_channels, output_channels)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv_down(x)\n",
    "class UpConv(nn.Module): \n",
    "    def __init__(self, input_channels, output_channels, padding=0):\n",
    "        super().__init__()\n",
    "        self.conv_up = nn.Sequential(\n",
    "            nn.ConvTranspose2d(input_channels , input_channels // 2, kernel_size=2, stride=2, padding = padding),\n",
    "        )\n",
    "        self.conv_level = nn.Sequential(\n",
    "            UNetConv(input_channels,output_channels) \n",
    "        )\n",
    "    def forward(self, x1, x2):\n",
    "        return self.conv_level(torch.cat([x2,self.conv_up(x1)],dim = 1)) \n",
    "class LastConv(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super().__init__()\n",
    "        self.conv_final = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, output_channels, kernel_size=1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv_final(x)\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, input_channels, max_channels):\n",
    "        super(UNet, self).__init__()\n",
    "        self.current_channels = max_channels // 2**4\n",
    "        self.start = UNetConv(input_channels, self.current_channels)\n",
    "        self.current_channels = self.current_channels*2\n",
    "        self.down1 = DownConv(self.current_channels // 2 , self.current_channels)\n",
    "        self.current_channels = self.current_channels*2\n",
    "        self.down2 = DownConv(self.current_channels // 2 , self.current_channels)\n",
    "        self.current_channels = self.current_channels*2\n",
    "        self.down3 = DownConv(self.current_channels // 2 , self.current_channels)\n",
    "        #self.current_channels = self.current_channels*2\n",
    "        #self.down4 = DownConv(self.current_channels // 2 , self.current_channels)\n",
    "        #self.current_channels = self.current_channels // 2\n",
    "        #self.up1 = UpConv(self.current_channels * 2, self.current_channels) \n",
    "        self.current_channels = self.current_channels // 2\n",
    "        self.up2 = UpConv(self.current_channels * 2, self.current_channels)\n",
    "        self.current_channels = self.current_channels // 2\n",
    "        self.up3 = UpConv(self.current_channels * 2, self.current_channels)\n",
    "        self.current_channels = self.current_channels // 2\n",
    "        self.up4 = UpConv(self.current_channels * 2, self.current_channels)\n",
    "        self.final = LastConv(self.current_channels,output_classes)\n",
    "    def forward(self, x):\n",
    "        x1 = self.start(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        #x5 = self.down4(x4)\n",
    "        #y1 = self.up1(x5,x4)\n",
    "        y2 = self.up2(x4,x3) #x4 was y1 earlier\n",
    "        y3 = self.up3(y2,x2) \n",
    "        x = self.up4(y3,x1)\n",
    "        return torch.sigmoid(self.final(x))\n",
    "\n",
    "if(pretrained):\n",
    "    Model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=3, out_channels=1, init_features=32, pretrained=True)\n",
    "    Model = Model.train(True).to(device)    \n",
    "    for parents in Model.children():\n",
    "        for count, child in enumerate(parents.children()):\n",
    "            if count == freeze_layers:\n",
    "                break\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad=False\n",
    "else:\n",
    "    Model = UNet(input_channels, max_channels)\n",
    "    Model = Model.to(device)\n",
    "\n",
    "if(use_gpu):\n",
    "    Model = nn.DataParallel(Model, device_ids = [i for i in range(torch.cuda.device_count())]).to(0)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(Model.parameters(),lr=learning_rate)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using cache found in /Users/siddhant/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
    "    f_path = checkpoint_path\n",
    "    torch.save(state, f_path)\n",
    "    if is_best:\n",
    "        best_fpath = best_model_path\n",
    "        shutil.copyfile(f_path, best_fpath)\n",
    "def load_ckp(checkpoint_fpath, model, optimizer):\n",
    "    if(use_gpu==False):\n",
    "        checkpoint = torch.load(checkpoint_fpath,map_location=torch.device('cpu'))\n",
    "    else:\n",
    "        checkpoint = torch.load(checkpoint_fpath)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    loss = checkpoint['loss']\n",
    "    acc = checkpoint['accuracy']\n",
    "    return model, optimizer, checkpoint['epoch'], loss, acc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training Model:\n",
    "=="
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "epochs = epoch_number\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = dice_alpha #maybe try 1e-4\n",
    "    def forward(self, y_pred, y_true):\n",
    "        assert y_pred.size() == y_true.size()\n",
    "        y_pred = y_pred[:, 0].contiguous().view(-1)\n",
    "        y_true = y_true[:, 0].contiguous().view(-1)\n",
    "        intersection = (y_pred * y_true).sum()\n",
    "        dsc = (2. * intersection + self.smooth) / (y_pred.sum() + y_true.sum() + self.smooth)\n",
    "        return 1. - dsc\n",
    "\n",
    "loss_func = DiceLoss()\n",
    "acc_sanity = jsc\n",
    "trainLoss = []\n",
    "sanityAccc = []\n",
    "liveloss = PlotLosses()\n",
    "for epoch in range(epochs):  \n",
    "    epochStart = time.time()\n",
    "    runningLoss = 0.0\n",
    "    sanityAcc = 0.0\n",
    "    i = 0\n",
    "    for inputs, labels in tqdm(train_dataLoader): \n",
    "        if(i==3):\n",
    "            break\n",
    "        inputs = inputs.to(device)\n",
    "        if(use_gpu):\n",
    "            inputs = inputs.to(0)\n",
    "        labels = labels.to(device)\n",
    "        if(pretrained):\n",
    "            inputs = torchvision.transforms.Resize((256,256))(inputs)\n",
    "        optimizer.zero_grad()  \n",
    "        outputs = Model(inputs) \n",
    "        outputs = torchvision.transforms.Resize((750,750))(outputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward() \n",
    "        acc_san = acc_sanity(torch.round(outputs).cpu().detach().numpy().reshape(-1), labels.cpu().detach().numpy().reshape(-1))\n",
    "        nn.utils.clip_grad_norm_(Model.parameters(), gradient_clip)\n",
    "        optimizer.step()\n",
    "        runningLoss += loss.item()\n",
    "        sanityAcc += acc_san.item()\n",
    "    runningLoss *= batch_size/train_size\n",
    "    sanityAcc *= batch_size/train_size\n",
    "    logs = {}\n",
    "    logs['loss'] = runningLoss\n",
    "    logs['accuracy'] = sanityAcc\n",
    "    liveloss.update(logs)\n",
    "    liveloss.send()\n",
    "    checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'loss': runningLoss,\n",
    "            'state_dict': Model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'accuracy' : sanityAcc,\n",
    "        }\n",
    "    save_ckp(checkpoint, False, PATH, bestPATH)\n",
    "    # do this for validation loss \n",
    "    if runningLoss <= runningLoss_min:\n",
    "        print('Loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(runningLoss_min,runningLoss))\n",
    "        save_ckp(checkpoint, True, PATH, bestPATH)\n",
    "        runningLoss_min = runningLoss\n",
    "    sanityAccc.append(sanityAcc)\n",
    "    trainLoss.append(runningLoss)\n",
    "    epochEnd = time.time()-epochStart\n",
    "    print('Iteration: {:.0f} /{:.0f}  ;  Training Loss: {:.6f} ; Jaccard Score: {:.6f} ; Time consumed: {:.0f}m {:.0f}s '\\\n",
    "        .format(epoch + 1, epochs, runningLoss, sanityAcc, epochEnd//60, epochEnd%60))   \n",
    "print('Finished Training')"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fb7689c29db44908a1e7e9bc2aafef24"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "plt.plot([i+1 for i in range(epochs)],trainLoss)\n",
    "plt.plot([i+1 for i in range(epochs)], sanityAccc)\n",
    "checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'loss': runningLoss,\n",
    "            'state_dict': Model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'accuracy' : sanityAcc,\n",
    "        }\n",
    "save_ckp(checkpoint, True, PATH, bestPATH)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing Model:\n",
    "=="
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "Model, optimizer, epoch, loss, acc = load_ckp(bestPATH,Model,optimizer) #use bestPATH with name test, and don't overwrite it via above script\n",
    "Model.eval()\n",
    "i = 0\n",
    "for inputs in tqdm(test_dataLoader):\n",
    "    i+=1\n",
    "    outputs = Model(inputs)\n",
    "    outputs = torchvision.transforms.Resize((750,750))(outputs).cpu().detach().numpy().reshape((750,750))\n",
    "    plt.imshow(outputs)\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(5,5)\n",
    "    print(\"Index \"+str(i)+\": \")\n",
    "    plt.show()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for UNet:\n\tMissing key(s) in state_dict: \"encoder1.enc1conv1.weight\", \"encoder1.enc1norm1.weight\", \"encoder1.enc1norm1.bias\", \"encoder1.enc1norm1.running_mean\", \"encoder1.enc1norm1.running_var\", \"encoder1.enc1conv2.weight\", \"encoder1.enc1norm2.weight\", \"encoder1.enc1norm2.bias\", \"encoder1.enc1norm2.running_mean\", \"encoder1.enc1norm2.running_var\", \"encoder2.enc2conv1.weight\", \"encoder2.enc2norm1.weight\", \"encoder2.enc2norm1.bias\", \"encoder2.enc2norm1.running_mean\", \"encoder2.enc2norm1.running_var\", \"encoder2.enc2conv2.weight\", \"encoder2.enc2norm2.weight\", \"encoder2.enc2norm2.bias\", \"encoder2.enc2norm2.running_mean\", \"encoder2.enc2norm2.running_var\", \"encoder3.enc3conv1.weight\", \"encoder3.enc3norm1.weight\", \"encoder3.enc3norm1.bias\", \"encoder3.enc3norm1.running_mean\", \"encoder3.enc3norm1.running_var\", \"encoder3.enc3conv2.weight\", \"encoder3.enc3norm2.weight\", \"encoder3.enc3norm2.bias\", \"encoder3.enc3norm2.running_mean\", \"encoder3.enc3norm2.running_var\", \"encoder4.enc4conv1.weight\", \"encoder4.enc4norm1.weight\", \"encoder4.enc4norm1.bias\", \"encoder4.enc4norm1.running_mean\", \"encoder4.enc4norm1.running_var\", \"encoder4.enc4conv2.weight\", \"encoder4.enc4norm2.weight\", \"encoder4.enc4norm2.bias\", \"encoder4.enc4norm2.running_mean\", \"encoder4.enc4norm2.running_var\", \"bottleneck.bottleneckconv1.weight\", \"bottleneck.bottlenecknorm1.weight\", \"bottleneck.bottlenecknorm1.bias\", \"bottleneck.bottlenecknorm1.running_mean\", \"bottleneck.bottlenecknorm1.running_var\", \"bottleneck.bottleneckconv2.weight\", \"bottleneck.bottlenecknorm2.weight\", \"bottleneck.bottlenecknorm2.bias\", \"bottleneck.bottlenecknorm2.running_mean\", \"bottleneck.bottlenecknorm2.running_var\", \"upconv4.weight\", \"upconv4.bias\", \"decoder4.dec4conv1.weight\", \"decoder4.dec4norm1.weight\", \"decoder4.dec4norm1.bias\", \"decoder4.dec4norm1.running_mean\", \"decoder4.dec4norm1.running_var\", \"decoder4.dec4conv2.weight\", \"decoder4.dec4norm2.weight\", \"decoder4.dec4norm2.bias\", \"decoder4.dec4norm2.running_mean\", \"decoder4.dec4norm2.running_var\", \"upconv3.weight\", \"upconv3.bias\", \"decoder3.dec3conv1.weight\", \"decoder3.dec3norm1.weight\", \"decoder3.dec3norm1.bias\", \"decoder3.dec3norm1.running_mean\", \"decoder3.dec3norm1.running_var\", \"decoder3.dec3conv2.weight\", \"decoder3.dec3norm2.weight\", \"decoder3.dec3norm2.bias\", \"decoder3.dec3norm2.running_mean\", \"decoder3.dec3norm2.running_var\", \"upconv2.weight\", \"upconv2.bias\", \"decoder2.dec2conv1.weight\", \"decoder2.dec2norm1.weight\", \"decoder2.dec2norm1.bias\", \"decoder2.dec2norm1.running_mean\", \"decoder2.dec2norm1.running_var\", \"decoder2.dec2conv2.weight\", \"decoder2.dec2norm2.weight\", \"decoder2.dec2norm2.bias\", \"decoder2.dec2norm2.running_mean\", \"decoder2.dec2norm2.running_var\", \"upconv1.weight\", \"upconv1.bias\", \"decoder1.dec1conv1.weight\", \"decoder1.dec1norm1.weight\", \"decoder1.dec1norm1.bias\", \"decoder1.dec1norm1.running_mean\", \"decoder1.dec1norm1.running_var\", \"decoder1.dec1conv2.weight\", \"decoder1.dec1norm2.weight\", \"decoder1.dec1norm2.bias\", \"decoder1.dec1norm2.running_mean\", \"decoder1.dec1norm2.running_var\", \"conv.weight\", \"conv.bias\". \n\tUnexpected key(s) in state_dict: \"module.encoder1.enc1conv1.weight\", \"module.encoder1.enc1norm1.weight\", \"module.encoder1.enc1norm1.bias\", \"module.encoder1.enc1norm1.running_mean\", \"module.encoder1.enc1norm1.running_var\", \"module.encoder1.enc1norm1.num_batches_tracked\", \"module.encoder1.enc1conv2.weight\", \"module.encoder1.enc1norm2.weight\", \"module.encoder1.enc1norm2.bias\", \"module.encoder1.enc1norm2.running_mean\", \"module.encoder1.enc1norm2.running_var\", \"module.encoder1.enc1norm2.num_batches_tracked\", \"module.encoder2.enc2conv1.weight\", \"module.encoder2.enc2norm1.weight\", \"module.encoder2.enc2norm1.bias\", \"module.encoder2.enc2norm1.running_mean\", \"module.encoder2.enc2norm1.running_var\", \"module.encoder2.enc2norm1.num_batches_tracked\", \"module.encoder2.enc2conv2.weight\", \"module.encoder2.enc2norm2.weight\", \"module.encoder2.enc2norm2.bias\", \"module.encoder2.enc2norm2.running_mean\", \"module.encoder2.enc2norm2.running_var\", \"module.encoder2.enc2norm2.num_batches_tracked\", \"module.encoder3.enc3conv1.weight\", \"module.encoder3.enc3norm1.weight\", \"module.encoder3.enc3norm1.bias\", \"module.encoder3.enc3norm1.running_mean\", \"module.encoder3.enc3norm1.running_var\", \"module.encoder3.enc3norm1.num_batches_tracked\", \"module.encoder3.enc3conv2.weight\", \"module.encoder3.enc3norm2.weight\", \"module.encoder3.enc3norm2.bias\", \"module.encoder3.enc3norm2.running_mean\", \"module.encoder3.enc3norm2.running_var\", \"module.encoder3.enc3norm2.num_batches_tracked\", \"module.encoder4.enc4conv1.weight\", \"module.encoder4.enc4norm1.weight\", \"module.encoder4.enc4norm1.bias\", \"module.encoder4.enc4norm1.running_mean\", \"module.encoder4.enc4norm1.running_var\", \"module.encoder4.enc4norm1.num_batches_tracked\", \"module.encoder4.enc4conv2.weight\", \"module.encoder4.enc4norm2.weight\", \"module.encoder4.enc4norm2.bias\", \"module.encoder4.enc4norm2.running_mean\", \"module.encoder4.enc4norm2.running_var\", \"module.encoder4.enc4norm2.num_batches_tracked\", \"module.bottleneck.bottleneckconv1.weight\", \"module.bottleneck.bottlenecknorm1.weight\", \"module.bottleneck.bottlenecknorm1.bias\", \"module.bottleneck.bottlenecknorm1.running_mean\", \"module.bottleneck.bottlenecknorm1.running_var\", \"module.bottleneck.bottlenecknorm1.num_batches_tracked\", \"module.bottleneck.bottleneckconv2.weight\", \"module.bottleneck.bottlenecknorm2.weight\", \"module.bottleneck.bottlenecknorm2.bias\", \"module.bottleneck.bottlenecknorm2.running_mean\", \"module.bottleneck.bottlenecknorm2.running_var\", \"module.bottleneck.bottlenecknorm2.num_batches_tracked\", \"module.upconv4.weight\", \"module.upconv4.bias\", \"module.decoder4.dec4conv1.weight\", \"module.decoder4.dec4norm1.weight\", \"module.decoder4.dec4norm1.bias\", \"module.decoder4.dec4norm1.running_mean\", \"module.decoder4.dec4norm1.running_var\", \"module.decoder4.dec4norm1.num_batches_tracked\", \"module.decoder4.dec4conv2.weight\", \"module.decoder4.dec4norm2.weight\", \"module.decoder4.dec4norm2.bias\", \"module.decoder4.dec4norm2.running_mean\", \"module.decoder4.dec4norm2.running_var\", \"module.decoder4.dec4norm2.num_batches_tracked\", \"module.upconv3.weight\", \"module.upconv3.bias\", \"module.decoder3.dec3conv1.weight\", \"module.decoder3.dec3norm1.weight\", \"module.decoder3.dec3norm1.bias\", \"module.decoder3.dec3norm1.running_mean\", \"module.decoder3.dec3norm1.running_var\", \"module.decoder3.dec3norm1.num_batches_tracked\", \"module.decoder3.dec3conv2.weight\", \"module.decoder3.dec3norm2.weight\", \"module.decoder3.dec3norm2.bias\", \"module.decoder3.dec3norm2.running_mean\", \"module.decoder3.dec3norm2.running_var\", \"module.decoder3.dec3norm2.num_batches_tracked\", \"module.upconv2.weight\", \"module.upconv2.bias\", \"module.decoder2.dec2conv1.weight\", \"module.decoder2.dec2norm1.weight\", \"module.decoder2.dec2norm1.bias\", \"module.decoder2.dec2norm1.running_mean\", \"module.decoder2.dec2norm1.running_var\", \"module.decoder2.dec2norm1.num_batches_tracked\", \"module.decoder2.dec2conv2.weight\", \"module.decoder2.dec2norm2.weight\", \"module.decoder2.dec2norm2.bias\", \"module.decoder2.dec2norm2.running_mean\", \"module.decoder2.dec2norm2.running_var\", \"module.decoder2.dec2norm2.num_batches_tracked\", \"module.upconv1.weight\", \"module.upconv1.bias\", \"module.decoder1.dec1conv1.weight\", \"module.decoder1.dec1norm1.weight\", \"module.decoder1.dec1norm1.bias\", \"module.decoder1.dec1norm1.running_mean\", \"module.decoder1.dec1norm1.running_var\", \"module.decoder1.dec1norm1.num_batches_tracked\", \"module.decoder1.dec1conv2.weight\", \"module.decoder1.dec1norm2.weight\", \"module.decoder1.dec1norm2.bias\", \"module.decoder1.dec1norm2.running_mean\", \"module.decoder1.dec1norm2.running_var\", \"module.decoder1.dec1norm2.num_batches_tracked\", \"module.conv.weight\", \"module.conv.bias\". ",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e15434b40d39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_ckp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbestPATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#use bestPATH with name test, and don't overwrite it via above script\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-b169e2720608>\u001b[0m in \u001b[0;36mload_ckp\u001b[0;34m(checkpoint_fpath, model, optimizer)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_fpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.2/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1407\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for UNet:\n\tMissing key(s) in state_dict: \"encoder1.enc1conv1.weight\", \"encoder1.enc1norm1.weight\", \"encoder1.enc1norm1.bias\", \"encoder1.enc1norm1.running_mean\", \"encoder1.enc1norm1.running_var\", \"encoder1.enc1conv2.weight\", \"encoder1.enc1norm2.weight\", \"encoder1.enc1norm2.bias\", \"encoder1.enc1norm2.running_mean\", \"encoder1.enc1norm2.running_var\", \"encoder2.enc2conv1.weight\", \"encoder2.enc2norm1.weight\", \"encoder2.enc2norm1.bias\", \"encoder2.enc2norm1.running_mean\", \"encoder2.enc2norm1.running_var\", \"encoder2.enc2conv2.weight\", \"encoder2.enc2norm2.weight\", \"encoder2.enc2norm2.bias\", \"encoder2.enc2norm2.running_mean\", \"encoder2.enc2norm2.running_var\", \"encoder3.enc3conv1.weight\", \"encoder3.enc3norm1.weight\", \"encoder3.enc3norm1.bias\", \"encoder3.enc3norm1.running_mean\", \"encoder3.enc3norm1.running_var\", \"encoder3.enc3conv2.weight\", \"encoder3.enc3norm2.weight\", \"encoder3.enc3norm2.bias\", \"encoder3.enc3norm2.running_mean\", \"encoder3.enc3norm2.running_var\", \"encoder4.enc4conv1.weight\", \"encoder4.enc4norm1.weight\", \"encoder4.enc4norm1.bias\", \"encoder4.enc4norm1.running_mean\", \"encoder4.enc4norm1.running_var\", \"encoder4.enc4conv2.weight\", \"encoder4.enc4norm2.weight\", \"encoder4.enc4norm2.bias\", \"encoder4.enc4norm2.running_mean\", \"encoder4.enc4norm2.running_var\", \"bottleneck.bottleneckconv1.weight\", \"bottleneck.bottlenecknorm1.weight\", \"bottleneck.bottlenecknorm1.bias\", \"bottleneck.bottlenecknorm1.running_mean\", \"bottleneck.bottlenecknorm1.running_var\", \"bottleneck.bottleneckconv2.weight\", \"bottleneck.bottlenecknorm2.weight\", \"bottleneck.bottlenecknorm2.bias\", \"bottleneck.bottlenecknorm2.running_mean\", \"bottleneck.bottlenecknorm2.running_var\", \"upconv4.weight\", \"upconv4.bias\", \"decoder4.dec4conv1.weight\", \"decoder4.dec4norm1.weight\", \"decoder4.dec4norm1.bias\", \"decoder4.dec4norm1.running_mean\", \"decoder4.dec4norm1.running_var\", \"decoder4.dec4conv2.weight\", \"decoder4.dec4norm2.weight\", \"decoder4.dec4norm2.bias\", \"decoder4.dec4norm2.running_mean\", \"decoder4.dec4norm2.running_var\", \"upconv3.weight\", \"upconv3.bias\", \"decoder3.dec3conv1.weight\", \"decoder3.dec3norm1.weight\", \"decoder3.dec3norm1.bias\", \"decoder3.dec3norm1.running_mean\", \"decoder3.dec3norm1.running_var\", \"decoder3.dec3conv2.weight\", \"decoder3.dec3norm2.weight\", \"decoder3.dec3norm2.bias\", \"decoder3.dec3norm2.running_mean\", \"decoder3.dec3norm2.running_var\", \"upconv2.weight\", \"upconv2.bias\", \"decoder2.dec2conv1.weight\", \"decoder2.dec2norm1.weight\", \"decoder2.dec2norm1.bias\", \"decoder2.dec2norm1.running_mean\", \"decoder2.dec2norm1.running_var\", \"decoder2.dec2conv2.weight\", \"decoder2.dec2norm2.weight\", \"decoder2.dec2norm2.bias\", \"decoder2.dec2norm2.running_mean\", \"decoder2.dec2norm2.running_var\", \"upconv1.weight\", \"upconv1.bias\", \"decoder1.dec1conv1.weight\", \"decoder1.dec1norm1.weight\", \"decoder1.dec1norm1.bias\", \"decoder1.dec1norm1.running_mean\", \"decoder1.dec1norm1.running_var\", \"decoder1.dec1conv2.weight\", \"decoder1.dec1norm2.weight\", \"decoder1.dec1norm2.bias\", \"decoder1.dec1norm2.running_mean\", \"decoder1.dec1norm2.running_var\", \"conv.weight\", \"conv.bias\". \n\tUnexpected key(s) in state_dict: \"module.encoder1.enc1conv1.weight\", \"module.encoder1.enc1norm1.weight\", \"module.encoder1.enc1norm1.bias\", \"module.encoder1.enc1norm1.running_mean\", \"module.encoder1.enc1norm1.running_var\", \"module.encoder1.enc1norm1.num_batches_tracked\", \"module.encoder1.enc1conv2.weight\", \"module.encoder1.enc1norm2.weight\", \"module.encoder1.enc1norm2.bias\", \"module.encoder1.enc1norm2.running_mean\", \"module.encoder1.enc1norm2.running_var\", \"module.encoder1.enc1norm2.num_batches_tracked\", \"module.encoder2.enc2conv1.weight\", \"module.encoder2.enc2norm1.weight\", \"module.encoder2.enc2norm1.bias\", \"module.encoder2.enc2norm1.running_mean\", \"module.encoder2.enc2norm1.running_var\", \"module.encoder2.enc2norm1.num_batches_tracked\", \"module.encoder2.enc2conv2.weight\", \"module.encoder2.enc2norm2.weight\", \"module.encoder2.enc2norm2.bias\", \"module.encoder2.enc2norm2.running_mean\", \"module.encoder2.enc2norm2.running_var\", \"module.encoder2.enc2norm2.num_batches_tracked\", \"module.encoder3.enc3conv1.weight\", \"module.encoder3.enc3norm1.weight\", \"module.encoder3.enc3norm1.bias\", \"module.encoder3.enc3norm1.running_mean\", \"module.encoder3.enc3norm1.running_var\", \"module.encoder3.enc3norm1.num_batches_tracked\", \"module.encoder3.enc3conv2.weight\", \"module.encoder3.enc3norm2.weight\", \"module.encoder3.enc3norm2.bias\", \"module.encoder3.enc3norm2.running_mean\", \"module.encoder3.enc3norm2.running_var\", \"module.encoder3.enc3norm2.num_batches_tracked\", \"module.encoder4.enc4conv1.weight\", \"module.encoder4.enc4norm1.weight\", \"module.encoder4.enc4norm1.bias\", \"module.encoder4.enc4norm1.running_mean\", \"module.encoder4.enc4norm1.running_var\", \"module.encoder4.enc4norm1.num_batches_tracked\", \"module.encoder4.enc4conv2.weight\", \"module.encoder4.enc4norm2.weight\", \"module.encoder4.enc4norm2.bias\", \"module.encoder4.enc4norm2.running_mean\", \"module.encoder4.enc4norm2.running_var\", \"module.encoder4.enc4norm2.num_batches_tracked\", \"module.bottleneck.bottleneckconv1.weight\", \"module.bottleneck.bottlenecknorm1.weight\", \"module.bottleneck.bottlenecknorm1.bias\", \"module.bottleneck.bottlenecknorm1.running_mean\", \"module.bottleneck.bottlenecknorm1.running_var\", \"module.bottleneck.bottlenecknorm1.num_batches_tracked\", \"module.bottleneck.bottleneckconv2.weight\", \"module.bottleneck.bottlenecknorm2.weight\", \"module.bottleneck.bottlenecknorm2.bias\", \"module.bottleneck.bottlenecknorm2.running_mean\", \"module.bottleneck.bottlenecknorm2.running_var\", \"module.bottleneck.bottlenecknorm2.num_batches_tracked\", \"module.upconv4.weight\", \"module.upconv4.bias\", \"module.decoder4.dec4conv1.weight\", \"module.decoder4.dec4norm1.weight\", \"module.decoder4.dec4norm1.bias\", \"module.decoder4.dec4norm1.running_mean\", \"module.decoder4.dec4norm1.running_var\", \"module.decoder4.dec4norm1.num_batches_tracked\", \"module.decoder4.dec4conv2.weight\", \"module.decoder4.dec4norm2.weight\", \"module.decoder4.dec4norm2.bias\", \"module.decoder4.dec4norm2.running_mean\", \"module.decoder4.dec4norm2.running_var\", \"module.decoder4.dec4norm2.num_batches_tracked\", \"module.upconv3.weight\", \"module.upconv3.bias\", \"module.decoder3.dec3conv1.weight\", \"module.decoder3.dec3norm1.weight\", \"module.decoder3.dec3norm1.bias\", \"module.decoder3.dec3norm1.running_mean\", \"module.decoder3.dec3norm1.running_var\", \"module.decoder3.dec3norm1.num_batches_tracked\", \"module.decoder3.dec3conv2.weight\", \"module.decoder3.dec3norm2.weight\", \"module.decoder3.dec3norm2.bias\", \"module.decoder3.dec3norm2.running_mean\", \"module.decoder3.dec3norm2.running_var\", \"module.decoder3.dec3norm2.num_batches_tracked\", \"module.upconv2.weight\", \"module.upconv2.bias\", \"module.decoder2.dec2conv1.weight\", \"module.decoder2.dec2norm1.weight\", \"module.decoder2.dec2norm1.bias\", \"module.decoder2.dec2norm1.running_mean\", \"module.decoder2.dec2norm1.running_var\", \"module.decoder2.dec2norm1.num_batches_tracked\", \"module.decoder2.dec2conv2.weight\", \"module.decoder2.dec2norm2.weight\", \"module.decoder2.dec2norm2.bias\", \"module.decoder2.dec2norm2.running_mean\", \"module.decoder2.dec2norm2.running_var\", \"module.decoder2.dec2norm2.num_batches_tracked\", \"module.upconv1.weight\", \"module.upconv1.bias\", \"module.decoder1.dec1conv1.weight\", \"module.decoder1.dec1norm1.weight\", \"module.decoder1.dec1norm1.bias\", \"module.decoder1.dec1norm1.running_mean\", \"module.decoder1.dec1norm1.running_var\", \"module.decoder1.dec1norm1.num_batches_tracked\", \"module.decoder1.dec1conv2.weight\", \"module.decoder1.dec1norm2.weight\", \"module.decoder1.dec1norm2.bias\", \"module.decoder1.dec1norm2.running_mean\", \"module.decoder1.dec1norm2.running_var\", \"module.decoder1.dec1norm2.num_batches_tracked\", \"module.conv.weight\", \"module.conv.bias\". "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d32307ab60c186a8047d52516f214c86ffc4fca0a07f2d9b7e263da528082b42"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}