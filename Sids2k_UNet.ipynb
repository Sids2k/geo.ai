{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Importing Libraries:\n",
    "=="
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "from sklearn.metrics import jaccard_score as jsc\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print('GPU is available!')\n",
    "    device = \"cuda\"\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor') \n",
    "else:\n",
    "    print('GPU is not available!')\n",
    "    device = \"cpu\""
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GPU is not available!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading Data:\n",
    "=="
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class DataSet(nn.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.image_names= os.listdir('./Data_ML/image_chips/')\n",
    "    def __getitem__(self, index):\n",
    "        image = plt.imread(os.path.join(os.getcwd(),'Data_ML','image_chips',self.image_names[index]))\n",
    "        mask = pd.read_csv(os.path.join(os.getcwd(),'Data_ML','target_feature_AOI',self.image_names[index][:-4]+'.csv'))\n",
    "        coordinates = mask.WKT.values[0][16:-3].split(',')\n",
    "        # convert coordinates into a masked image (750x750x1)\n",
    "        masked_image = coordinates  #placeholder\n",
    "        return image, masked_image\n",
    "    def __len__(self):\n",
    "        return 100 #cause we have 100 samples, change this if needed"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# input training images are 750x750x3 and are 100 in number\n",
    "# test image is 5x5 images (hence 3750x3750x3), we need to output a masked image with 0s and 1s\n",
    "input_channels = 3 \n",
    "max_channels = 512\n",
    "output_classes = 1\n",
    "\n",
    "batch_size = 16\n",
    "train_size = 100 # divide train:val by 70:30 probably\n",
    "test_size = 25 # if we break the super test image into individual images to run our model on"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating Module:\n",
    "=="
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "class UNetConv(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super().__init__()\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, output_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(output_channels, output_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(output_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv2(x)\n",
    "class DownConv(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super().__init__()\n",
    "        self.conv_down = nn.Sequential(\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            UNetConv(input_channels, output_channels)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv_down(x)\n",
    "class UpConv(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super().__init__()\n",
    "        self.conv_up = nn.Sequential(\n",
    "            nn.ConvTranspose2d(input_channels , input_channels // 2, kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.conv_level = nn.Sequential(\n",
    "            UNetConv(input_channels,output_channels)\n",
    "        )\n",
    "    def forward(self, x1, x2):\n",
    "        return self.conv_level(torch.cat([x2,self.conv_up(x1)],dim = 1))\n",
    "class LastConv(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super().__init__()\n",
    "        self.conv_final = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, output_channels, kernel_size=1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv_final(x)\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, input_channels, max_channels):\n",
    "        super(UNet, self).__init__()\n",
    "        self.current_channels = max_channels // 2**4\n",
    "        self.start = UNetConv(input_channels, self.current_channels)\n",
    "        self.current_channels = self.current_channels*2\n",
    "        self.down1 = DownConv(self.current_channels // 2 , self.current_channels)\n",
    "        self.current_channels = self.current_channels*2\n",
    "        self.down2 = DownConv(self.current_channels // 2 , self.current_channels)\n",
    "        self.current_channels = self.current_channels*2\n",
    "        self.down3 = DownConv(self.current_channels // 2 , self.current_channels)\n",
    "        self.current_channels = self.current_channels*2\n",
    "        self.down4 = DownConv(self.current_channels // 2 , self.current_channels)\n",
    "        self.current_channels = self.current_channels // 2\n",
    "        self.up1 = UpConv(self.current_channels * 2, self.current_channels) \n",
    "        self.current_channels = self.current_channels // 2\n",
    "        self.up2 = UpConv(self.current_channels * 2, self.current_channels)\n",
    "        self.current_channels = self.current_channels // 2\n",
    "        self.up3 = UpConv(self.current_channels * 2, self.current_channels)\n",
    "        self.current_channels = self.current_channels // 2\n",
    "        self.up4 = UpConv(self.current_channels * 2, self.current_channels)\n",
    "        self.final = LastConv(self.current_channels,output_classes)\n",
    "    def forward(self, x):\n",
    "        x1 = self.start(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4) \n",
    "        x = self.up4(self.up3(self.up2(self.up1(x5,x4),x3),x2),x1)\n",
    "        return torch.sigmoid(self.final(x))\n",
    "\n",
    "Model = UNet(input_channels, max_channels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training Model:\n",
    "=="
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "epochs = 5\n",
    "loss_func = jsc\n",
    "optimizer = optim.Adam(Model.parameters(),lr=0.01)\n",
    "\n",
    "trainLoss = []\n",
    "for epoch in range(epochs):  \n",
    "    epochStart = time.time()\n",
    "    runningLoss = 0.0\n",
    "    for inputs, labels in tqdm(train_dataLoader): \n",
    "        optimizer.zero_grad()  \n",
    "        outputs = Model(inputs)  \n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward() \n",
    "        nn.utils.clip_grad_norm_(Model.parameters(), 50)\n",
    "        optimizer.step()\n",
    "        runningLoss += loss.item()\n",
    "        \n",
    "    runningLoss /= len(inputs) \n",
    "    trainLoss.append(runningLoss)\n",
    "    epochEnd = time.time()-epochStart\n",
    "    print('Iteration: {:.0f} /{:.0f}  ;  Training Loss: {:.6f} ; Time consumed: {:.0f}m {:.0f}s '\\\n",
    "        .format(epoch + 1, epochs, runningLoss, epochEnd//60, epochEnd%60))   \n",
    "print('Finished Training')"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_dataLoader' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-8681acbb36f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mepochStart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mrunningLoss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# need to add the train data via a data loader like \\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# https://github.com/mateuszbuda/brain-segmentation-pytorch/blob/master/dataset.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataLoader' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing Model:\n",
    "=="
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "test_loss = 0.0\n",
    "for inputs, labels in tqdm(test_dataLoader):\n",
    "    outputs = Model(inputs)\n",
    "    loss = loss_func(outputs, labels)\n",
    "    test_loss += loss.item()\n",
    "test_loss /= len(inputs)\n",
    "print(test_loss)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'test_dataLoader' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7dd10115339d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dataLoader' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d32307ab60c186a8047d52516f214c86ffc4fca0a07f2d9b7e263da528082b42"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('shims': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}